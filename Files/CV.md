## Ziwei Zhang
---
## Career Objective
### **Machine Learning Engineer**
Master years are mainly focus on machine learning and deep learning algorithms and their applications. Capstone project was doing research on Fine Grained Visual Categorization. Experienced on Spark and Hadoop. 

---
## Education
* **The University of Sydney**
  
  2017.3 ~ Now

  Master of Information Technology and Information Management (Postgraduate)  Avg. 74/100

  Course: Algorithm(84)；Capstone Project(87)；Machine Learning and Data mining；Deep Learning；Advanced Network Technology

* **South China Agricultural University**(Guangdong '211') 
 
  2012.9 ~ 2016.6
  
  Electronic Information Engineering(BE)Avg. 85/100

  Course: Linear Algebra(84)；Digital Signal Processing(90)；Digital Electronic Technique；Embedded Linux System(83)

---
## Skills
* **Python Coding** training through LeetCode and TensorFlow project
* **Machine Learning** fostering by reading papers and doing Kaggle Program.
* **Deep Learning** knowledge about the CNN and RNN theories and structures. Experience in Deep Learning Project
* **Computer Vision** fostering by Fine Grained Visual Categorization project. Knowledge about the recently popular network as VGG16, InceptionV3 and DenseNet
* **Spark** Experienced in handling large data as well as the framework about spark and MapReduce.
* **Keras** learned from doing the Computer Vision Project
* **Java Coding** ; **Html** ; **CSS** 

---
## Project Experience
* **Utilizing Pretrained Model for Fine-Grained Species Classification** (2018.3 ~ 2018.6)
  
   We provide a theory that mix-combined background is able to improve the training performance. Firstly, using Mask-RCNN to isolate the foreground and background. Then, WGAN-GP is used to fill the missing pixel of the background and finally combined the foreground and background randomly to generate a new dataset. The new dataset contains the previous images and the newly generated images. It can improve the training performance with confirm.

* **Kaggle: What’s Cooking?** (2018.6 ~ Now)
    
    Analyse the ingredients from the meal .The dataset is pure text so I'm using the combination of TFIDF to quantify the text and then using SVM to classify them.

* **Kaggle: Forest Cover Type** (2018.6 ~ Now)

    This project is to analyse the features of a forest to predict its cover type. Recently the best result is using the AdaBoost (base_estimator = EtraTreesClassier). Data are purely numerics so normal feature engineering is enough.

* **Kaggle: MNIST** (2018.4 ~ 2018.5)
  
    It's a popular Contest of handwritten number classification. Using the fine-tuning Resnet37, the validate-accuracy is able to reach 99.98%. Resnet can improve the learning performance of bottom layers thanks to its shortcuts. For the future work, DenseNet will be taken into consideration. 



